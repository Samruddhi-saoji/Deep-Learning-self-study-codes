{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samruddhi-saoji/Deep-Learning-self-study-codes/blob/main/pre_trained_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9PZvoK1uZeF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZkXt6qN5Euu"
      },
      "source": [
        "### Dataset Handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_a6Pz0h5Iit"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, train_path=\"\", validation_path=\"\", test_path=\"\") -> None:\n",
        "        # set the parameters\n",
        "        self.train_path = train_path\n",
        "        self.test_path = test_path\n",
        "        self.vali=False #does vali set exist?\n",
        "        self.vali_path = \"\"\n",
        "        if validation_path != \"\":\n",
        "            self.vali = True #bool\n",
        "            self.vali_path = validation_path\n",
        "\n",
        "        # these values will be calculated when data is loaded\n",
        "        self.classes = []\n",
        "        self.num_classes = -1\n",
        "\n",
        "\n",
        "    # label_type = \"categorical\" for onehot encoding\n",
        "    def load_data(self, image_shape, label_type='int', batch_size=32) -> None:\n",
        "        #load the datasets\n",
        "        self.train_dataset = image_dataset_from_directory(\n",
        "            self.train_path,\n",
        "            image_size=image_shape,\n",
        "            batch_size=batch_size,\n",
        "            label_mode=label_type\n",
        "        )\n",
        "\n",
        "        self.test_dataset = image_dataset_from_directory(\n",
        "            self.test_path,\n",
        "            image_size=image_shape,\n",
        "            batch_size=batch_size,\n",
        "            label_mode=label_type\n",
        "        )\n",
        "\n",
        "        if self.vali_path != \"\":\n",
        "                self.vali_dataset = image_dataset_from_directory(\n",
        "                self.vali_path,\n",
        "                image_size=image_shape,\n",
        "                batch_size=batch_size,\n",
        "                label_mode=label_type\n",
        "            )\n",
        "\n",
        "        # get the classes\n",
        "        self.classes = self.train_dataset.class_names\n",
        "        self.num_classes = len(self.classes)\n",
        "\n",
        "        # get X, Y\n",
        "        X_train, Y_train = self.get_X_and_Y(self.train_dataset)\n",
        "        X_test, Y_test = self.get_X_and_Y(self.test_dataset)\n",
        "        X_vali, Y_vali = [], []\n",
        "        if self.vali:\n",
        "            X_vali, Y_vali = self.get_X_and_Y(self.vali_dataset)\n",
        "\n",
        "        return X_train, Y_train, X_vali, Y_vali, X_test, Y_test\n",
        "\n",
        "\n",
        "\n",
        "    # Convert datasets into arrays (optional, for X_train, Y_train, etc.)\n",
        "    def get_X_and_Y(self, dataset):\n",
        "        images = []\n",
        "        labels = []\n",
        "        for image_batch, label_batch in dataset:\n",
        "            images.append(image_batch.numpy())\n",
        "            labels.append(label_batch.numpy())\n",
        "        return np.concatenate(images), np.concatenate(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zulBCCyaxjoH"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pzDiNZD1jlZ"
      },
      "source": [
        "fruits 360 dataset\n",
        "\n",
        "Considering only these 7 classes:\n",
        " - Golden apple 1\n",
        " - Avocado\n",
        " - Lemon\n",
        " - Mango\n",
        " - Kiwi\n",
        " - Banana\n",
        " - Strawberry\n",
        " - Raspberry"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset"
      ],
      "metadata": {
        "id": "H0iPcs0Fzl0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-mULLLvxlSw",
        "outputId": "6a8140e5-19a1-433f-ea51-30c0b2e131ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Done once, no need to do it again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "xm5382Ugx1LB",
        "outputId": "d6005614-d380-4706-bbdf-f0d448d264fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3827 files belonging to 8 classes.\n",
            "Found 1285 files belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#feature scaling\\nX_train = X_train/255.0\\nX_test = X_test/255.0\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "img_shape = (100, 100)\n",
        "train_path = \"/content/drive/MyDrive/Datasets/kaggle fruits 360/fruits limited dataset/Training\"\n",
        "test_path = \"/content/drive/MyDrive/Datasets/kaggle fruits 360/fruits limited dataset/Test\"\n",
        "dataset = DataLoader(train_path=train_path, test_path=test_path)\n",
        "X_train, Y_train, _, __, X_test, Y_test = dataset.load_data(image_shape=img_shape)\n",
        "\n",
        "# shuffle data\n",
        "X_train, Y_train = shuffle(X_train, Y_train, random_state=42)\n",
        "X_test, Y_test = shuffle(X_test, Y_test, random_state=42)\n",
        "\n",
        "# dont do feature scaling for vgg\n",
        "'''#feature scaling\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data"
      ],
      "metadata": {
        "id": "ZlFAAEMszV2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Keras provides an inbuilt function to handle the data preprocessing.\n",
        "- Each pretrained model has diff recquirements, thus each has a diff preprocessing function"
      ],
      "metadata": {
        "id": "IxEoUD3UzyyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select correct model name\n",
        "# from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.resnet import preprocess_input\n",
        "\n",
        "# Preprocess data\n",
        "X_train = preprocess_input(X_train)\n",
        "X_test = preprocess_input(X_test)"
      ],
      "metadata": {
        "id": "5JBLRRrHzuqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks6u3-zpxg1U"
      },
      "source": [
        "# Pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten #layers"
      ],
      "metadata": {
        "id": "eQ6pv_MGvLzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss over the epochs\n",
        "def plot_loss(info):\n",
        "    plt.plot(info.history['loss'], label='Training loss', color='r')\n",
        "    plt.plot(info.history['val_loss'], label='Validation loss', color='b')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a7DH__azvoJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqfwugiBwx1r"
      },
      "source": [
        "## Vgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2yk8UjIaSND"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import preprocess_input, VGG16 #pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYZ6tpC7HAK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de9e06a-05c0-47e8-b7a2-3c509cbd8b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "''' Build the model '''\n",
        "\n",
        "input_shape = (100, 100, 3)\n",
        "\n",
        "# the base (convo-pooling) layers\n",
        "base = VGG16(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
        "\n",
        "# freeze all the base layers\n",
        "for layer in base.layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "# add Flattening and Dense layers to the base model\n",
        "x = Flatten()(base.output)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "y = Dense(8, activation='softmax')(x) #predicted output\n",
        "\n",
        "# create the final model\n",
        "model = Model(inputs=base.input, outputs=y)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK04k8Krw3Jg"
      },
      "source": [
        "## Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSe3V_N0yAw_"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet50 import ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Build the model '''\n",
        "\n",
        "input_shape = (100, 100, 3)\n",
        "\n",
        "# the base (convo-pooling) layers\n",
        "base = ResNet50(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
        "\n",
        "# freeze all the base layers\n",
        "for layer in base.layers:\n",
        "   layer.trainable = False\n",
        "\n",
        "# add Flattening and Dense layers to the base model\n",
        "x = Flatten()(base.output)\n",
        "x = Dense(10, activation='relu')(x)\n",
        "y = Dense(dataset.num_classes, activation='softmax')(x) #predicted output\n",
        "\n",
        "# create the final model\n",
        "model = Model(inputs=base.input, outputs=y)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "            )"
      ],
      "metadata": {
        "id": "rIJzag561W3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CULspCe4w6tQ"
      },
      "source": [
        "## Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a8z6AVWxWlm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhlUCYHDabdk"
      },
      "source": [
        "## Alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxm7Z2kWadMX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NKqcN5uadwk"
      },
      "source": [
        "## YOLO (You Only Look Once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7mHqgQdajwf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and testing"
      ],
      "metadata": {
        "id": "aox9r8ay9P_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Training and testing'''\n",
        "\n",
        "# Training and validation\n",
        "e = 3 #epochs\n",
        "info = model.fit(X_train, Y_train, epochs=e, validation_split=0.15)\n",
        "\n",
        "# plot train and vali loss\n",
        "plot_loss(info)\n",
        "\n",
        "# Testing\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test accuracy:{test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "OUyuLAUT9Ses"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi3O8rWdQto3+0gn2gcpd9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}